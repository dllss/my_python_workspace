#!/usr/bin/env python
# -*- coding: utf-8 -*-
"""
æ£€æŸ¥å¹¶æ¸…ç†æ‰€æœ‰è‚¡ç¥¨æ–‡ä»¶ä¸­çš„åœç‰Œæ•°æ®

åŠŸèƒ½ï¼š
    1. æ‰«æ data/CN ç›®å½•ä¸‹æ‰€æœ‰è‚¡ç¥¨æ–‡ä»¶
    2. æ£€æµ‹æ¯ä¸ªæ–‡ä»¶ä¸­æ˜¯å¦åŒ…å«åœç‰Œæ•°æ®
    3. è¿‡æ»¤åœç‰Œæ•°æ®å¹¶æ›´æ–°æ–‡ä»¶
    4. ç”Ÿæˆè¯¦ç»†çš„æ¸…ç†æŠ¥å‘Š

ä½¿ç”¨æ–¹æ³•ï¼š
    python scripts/clean_suspended_data.py
    æˆ–
    poetry run python scripts/clean_suspended_data.py
"""

import os
import sys
import pandas as pd
from datetime import datetime
from typing import List, Dict, Tuple

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°è·¯å¾„
sys.path.insert(0, os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

from config import OUTPUT_DIR, CN_DIR
from utils import filter_suspended_trading_data, MetadataManager


def scan_and_clean_suspended_data(data_dir: str, dry_run: bool = False) -> Dict:
    """
    æ‰«æå¹¶æ¸…ç†æ‰€æœ‰è‚¡ç¥¨æ–‡ä»¶ä¸­çš„åœç‰Œæ•°æ®
    
    Args:
        data_dir: æ•°æ®ç›®å½•è·¯å¾„
        dry_run: å¦‚æœä¸º Trueï¼Œåªæ£€æµ‹ä¸ä¿®æ”¹æ–‡ä»¶
    
    Returns:
        æ¸…ç†ç»Ÿè®¡ä¿¡æ¯
    """
    print("=" * 80)
    print("åœç‰Œæ•°æ®æ¸…ç†å·¥å…·")
    print("=" * 80)
    print(f"æ•°æ®ç›®å½•: {data_dir}")
    print(f"æ¨¡å¼: {'åªæ£€æµ‹ï¼ˆä¸ä¿®æ”¹ï¼‰' if dry_run else 'æ£€æµ‹å¹¶æ¸…ç†'}")
    print("=" * 80)
    print()
    
    # ç»Ÿè®¡ä¿¡æ¯
    stats = {
        'total_files': 0,
        'files_with_suspended': 0,
        'files_cleaned': 0,
        'total_records_removed': 0,
        'files_with_errors': 0,
        'details': []
    }
    
    # è·å–æ‰€æœ‰è‚¡ç¥¨æ–‡ä»¶
    stock_files = [f for f in os.listdir(data_dir) if f.startswith('stock_') and f.endswith('.csv')]
    stats['total_files'] = len(stock_files)
    
    if stats['total_files'] == 0:
        print("âš ï¸  æœªæ‰¾åˆ°ä»»ä½•è‚¡ç¥¨æ–‡ä»¶")
        return stats
    
    print(f"æ‰¾åˆ° {stats['total_files']} ä¸ªè‚¡ç¥¨æ–‡ä»¶")
    print()
    print("å¼€å§‹æ‰«æ...")
    print("-" * 80)
    
    # å¤„ç†æ¯ä¸ªæ–‡ä»¶
    for idx, filename in enumerate(sorted(stock_files), 1):
        filepath = os.path.join(data_dir, filename)
        stock_code = filename.replace('stock_', '').replace('.csv', '')
        
        try:
            # è¯»å–æ–‡ä»¶
            df = pd.read_csv(filepath, dtype={'è‚¡ç¥¨ä»£ç ': str})
            
            if df.empty:
                continue
            
            original_count = len(df)
            
            # æ£€æµ‹åœç‰Œæ•°æ®
            df_filtered, removed_count = filter_suspended_trading_data(df)
            
            if removed_count > 0:
                stats['files_with_suspended'] += 1
                stats['total_records_removed'] += removed_count
                
                # è®°å½•è¯¦ç»†ä¿¡æ¯
                detail = {
                    'stock_code': stock_code,
                    'filename': filename,
                    'original_count': original_count,
                    'removed_count': removed_count,
                    'remaining_count': len(df_filtered),
                    'removed_dates': []
                }
                
                # æ‰¾å‡ºè¢«ç§»é™¤çš„æ—¥æœŸï¼ˆä¿å­˜æ‰€æœ‰æ—¥æœŸï¼‰
                if 'æ—¥æœŸ' in df.columns:
                    removed_dates = set(df['æ—¥æœŸ']) - set(df_filtered['æ—¥æœŸ'])
                    detail['removed_dates'] = sorted(list(removed_dates))  # ä¿å­˜æ‰€æœ‰æ—¥æœŸ
                
                stats['details'].append(detail)
                
                # æ˜¾ç¤ºè¿›åº¦
                print(f"[{idx}/{stats['total_files']}] {stock_code}: å‘ç° {removed_count} æ¡åœç‰Œè®°å½•")
                
                # å¦‚æœä¸æ˜¯ dry_runï¼Œåˆ™æ›´æ–°æ–‡ä»¶
                if not dry_run:
                    if not df_filtered.empty:
                        # ä¿å­˜è¿‡æ»¤åçš„æ•°æ®
                        df_filtered.to_csv(filepath, index=False, encoding='utf-8-sig')
                        stats['files_cleaned'] += 1
                    else:
                        print(f"   âš ï¸  è­¦å‘Šï¼šè¿‡æ»¤åæ— æ•°æ®ï¼Œä¿ç•™åŸæ–‡ä»¶")
            else:
                # æ¯100ä¸ªæ–‡ä»¶æ˜¾ç¤ºä¸€æ¬¡è¿›åº¦
                if idx % 100 == 0:
                    print(f"[{idx}/{stats['total_files']}] å·²å¤„ç† {idx} ä¸ªæ–‡ä»¶...")
        
        except Exception as e:
            stats['files_with_errors'] += 1
            print(f"[{idx}/{stats['total_files']}] {stock_code}: âŒ é”™è¯¯ - {str(e)}")
    
    print("-" * 80)
    print()
    
    return stats


def update_metadata_after_cleaning(data_dir: str, cleaned_stocks: List[str]):
    """
    æ¸…ç†åæ›´æ–°å…ƒæ•°æ®
    
    Args:
        data_dir: æ•°æ®ç›®å½•
        cleaned_stocks: å·²æ¸…ç†çš„è‚¡ç¥¨ä»£ç åˆ—è¡¨
    """
    if not cleaned_stocks:
        return
    
    print("æ­£åœ¨æ›´æ–°å…ƒæ•°æ®...")
    
    try:
        metadata_mgr = MetadataManager(data_dir)
        
        for stock_code in cleaned_stocks:
            filepath = os.path.join(data_dir, f'stock_{stock_code}.csv')
            
            try:
                df = pd.read_csv(filepath, dtype={'è‚¡ç¥¨ä»£ç ': str})
                if not df.empty and 'æ—¥æœŸ' in df.columns:
                    last_date = df['æ—¥æœŸ'].max()
                    metadata_mgr.update_last_date(stock_code, last_date)
            except Exception as e:
                print(f"   âš ï¸  æ›´æ–° {stock_code} å…ƒæ•°æ®å¤±è´¥: {e}")
        
        print("âœ… å…ƒæ•°æ®æ›´æ–°å®Œæˆ")
    except Exception as e:
        print(f"âš ï¸  å…ƒæ•°æ®æ›´æ–°å¤±è´¥: {e}")


def print_report(stats: Dict, dry_run: bool):
    """
    æ‰“å°æ¸…ç†æŠ¥å‘Š
    
    Args:
        stats: ç»Ÿè®¡ä¿¡æ¯
        dry_run: æ˜¯å¦ä¸ºæ£€æµ‹æ¨¡å¼
    """
    print("=" * 80)
    print("æ¸…ç†æŠ¥å‘Š")
    print("=" * 80)
    print(f"æ€»æ–‡ä»¶æ•°: {stats['total_files']}")
    print(f"åŒ…å«åœç‰Œæ•°æ®çš„æ–‡ä»¶: {stats['files_with_suspended']}")
    
    if not dry_run:
        print(f"å·²æ¸…ç†çš„æ–‡ä»¶: {stats['files_cleaned']}")
    
    print(f"æ€»å…±ç§»é™¤è®°å½•æ•°: {stats['total_records_removed']}")
    print(f"å¤„ç†å‡ºé”™çš„æ–‡ä»¶: {stats['files_with_errors']}")
    print()
    
    if stats['files_with_suspended'] > 0:
        print("è¯¦ç»†ä¿¡æ¯ï¼ˆå‰20ä¸ªï¼Œå®Œæ•´åˆ—è¡¨è§æŠ¥å‘Šæ–‡ä»¶ï¼‰ï¼š")
        print("-" * 80)
        
        for detail in stats['details'][:20]:
            print(f"\nè‚¡ç¥¨ä»£ç : {detail['stock_code']}")
            print(f"  åŸå§‹è®°å½•: {detail['original_count']} æ¡")
            print(f"  ç§»é™¤è®°å½•: {detail['removed_count']} æ¡")
            print(f"  å‰©ä½™è®°å½•: {detail['remaining_count']} æ¡")
            
            if detail['removed_dates']:
                # åœ¨æ§åˆ¶å°åªæ˜¾ç¤ºå‰5ä¸ªæ—¥æœŸ
                dates_str = ', '.join(detail['removed_dates'][:5])
                if len(detail['removed_dates']) > 5:
                    dates_str += f" ... (å…± {len(detail['removed_dates'])} ä¸ªæ—¥æœŸï¼Œå®Œæ•´åˆ—è¡¨è§æŠ¥å‘Šæ–‡ä»¶)"
                print(f"  åœç‰Œæ—¥æœŸ: {dates_str}")
        
        if len(stats['details']) > 20:
            print(f"\n... è¿˜æœ‰ {len(stats['details']) - 20} ä¸ªæ–‡ä»¶åŒ…å«åœç‰Œæ•°æ®ï¼ˆå®Œæ•´åˆ—è¡¨è§æŠ¥å‘Šæ–‡ä»¶ï¼‰")
    
    print()
    print("=" * 80)
    
    if dry_run:
        print("ğŸ’¡ è¿™æ˜¯æ£€æµ‹æ¨¡å¼ï¼Œæœªä¿®æ”¹ä»»ä½•æ–‡ä»¶")
        print("   å¦‚éœ€æ¸…ç†ï¼Œè¯·è¿è¡Œ: python scripts/clean_suspended_data.py --clean")
    else:
        print("âœ… æ¸…ç†å®Œæˆï¼")


def main():
    """ä¸»å‡½æ•°"""
    import argparse
    
    parser = argparse.ArgumentParser(
        description='æ£€æŸ¥å¹¶æ¸…ç†æ‰€æœ‰è‚¡ç¥¨æ–‡ä»¶ä¸­çš„åœç‰Œæ•°æ®',
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
ç¤ºä¾‹:
  %(prog)s                    # åªæ£€æµ‹ï¼Œä¸ä¿®æ”¹æ–‡ä»¶
  %(prog)s --clean            # æ£€æµ‹å¹¶æ¸…ç†
  %(prog)s --clean --backup   # æ¸…ç†å‰å¤‡ä»½ï¼ˆæš‚æœªå®ç°ï¼‰
"""
    )
    
    parser.add_argument(
        '--clean',
        action='store_true',
        help='æ‰§è¡Œæ¸…ç†æ“ä½œï¼ˆé»˜è®¤åªæ£€æµ‹ï¼‰'
    )
    
    args = parser.parse_args()
    
    # æ„å»ºæ•°æ®ç›®å½•è·¯å¾„
    data_dir = os.path.join(OUTPUT_DIR, CN_DIR)
    
    if not os.path.exists(data_dir):
        print(f"âŒ æ•°æ®ç›®å½•ä¸å­˜åœ¨: {data_dir}")
        sys.exit(1)
    
    # æ‰§è¡Œæ‰«æå’Œæ¸…ç†
    dry_run = not args.clean
    stats = scan_and_clean_suspended_data(data_dir, dry_run=dry_run)
    
    # å¦‚æœæ‰§è¡Œäº†æ¸…ç†ï¼Œæ›´æ–°å…ƒæ•°æ®
    if args.clean and stats['files_cleaned'] > 0:
        cleaned_stocks = [d['stock_code'] for d in stats['details']]
        update_metadata_after_cleaning(data_dir, cleaned_stocks)
    
    # æ‰“å°æŠ¥å‘Š
    print_report(stats, dry_run)
    
    # ä¿å­˜è¯¦ç»†æŠ¥å‘Šåˆ°æ–‡ä»¶
    if stats['files_with_suspended'] > 0:
        report_file = os.path.join(data_dir, f"suspended_data_report_{datetime.now().strftime('%Y%m%d_%H%M%S')}.txt")
        
        try:
            with open(report_file, 'w', encoding='utf-8') as f:
                f.write("åœç‰Œæ•°æ®æ¸…ç†æŠ¥å‘Š\n")
                f.write("=" * 80 + "\n")
                f.write(f"ç”Ÿæˆæ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n")
                f.write(f"æ¨¡å¼: {'åªæ£€æµ‹' if dry_run else 'æ£€æµ‹å¹¶æ¸…ç†'}\n")
                f.write(f"æ€»æ–‡ä»¶æ•°: {stats['total_files']}\n")
                f.write(f"åŒ…å«åœç‰Œæ•°æ®çš„æ–‡ä»¶: {stats['files_with_suspended']}\n")
                f.write(f"æ€»å…±ç§»é™¤è®°å½•æ•°: {stats['total_records_removed']}\n")
                f.write("\nè¯¦ç»†ä¿¡æ¯:\n")
                f.write("-" * 80 + "\n")
                
                for detail in stats['details']:
                    f.write(f"\nè‚¡ç¥¨ä»£ç : {detail['stock_code']}\n")
                    f.write(f"  åŸå§‹è®°å½•: {detail['original_count']} æ¡\n")
                    f.write(f"  ç§»é™¤è®°å½•: {detail['removed_count']} æ¡\n")
                    f.write(f"  å‰©ä½™è®°å½•: {detail['remaining_count']} æ¡\n")
                    
                    if detail['removed_dates']:
                        f.write(f"  åœç‰Œæ—¥æœŸ: {', '.join(detail['removed_dates'])}\n")
            
            print(f"\nè¯¦ç»†æŠ¥å‘Šå·²ä¿å­˜åˆ°: {report_file}")
        
        except Exception as e:
            print(f"\nâš ï¸  ä¿å­˜æŠ¥å‘Šå¤±è´¥: {e}")


if __name__ == "__main__":
    main()
